
R version 3.5.0 (2018-04-23) -- "Joy in Playing"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R é um software livre e vem sem GARANTIA ALGUMA.
Você pode redistribuí-lo sob certas circunstâncias.
Digite 'license()' ou 'licence()' para detalhes de distribuição.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Digite 'demo()' para demonstrações, 'help()' para o sistema on-line de ajuda,
ou 'help.start()' para abrir o sistema de ajuda em HTML no seu navegador.
Digite 'q()' para sair do R.

[Área de trabalho anterior carregada]

> f <- function(net) {
+     return ( 1/(1+exp(-net)) )
+ }
> 
> df_dnet <- function(f_net) {
+     return (f_net * (1 - f_net))
+ }
> 
> mlp.architecture <- function(input.length=2,
+                              hidden.length=2,
+                              output.length=1,
+                              activation.function=f,
+                              d_activation.function=df_dnet) {
+ 
+     model = list()
+     model$input.length = input.length
+     model$hidden.length = hidden.length
+     model$output.length = output.length
+ 
+     model$hidden = matrix(runif(min=-0.5, max=0.5, 
+             hidden.length*(input.length+1)), 
+                    nrow=hidden.length, ncol=input.length+1)
+ 
+     model$output = matrix(runif(min=-0.5, max=0.5, 
+             output.length*(hidden.length+1)), 
+                    nrow=output.length, ncol=hidden.length+1)
+ 
+     model$f = activation.function
+     model$df_dnet = d_activation.function
+ 
+     return (model)
+ }
> 
> mlp.forward <- function(model, Xp) {
+     # Hidden layer
+     net_h_p = model$hidden %*% c(Xp, 1)
+     f_net_h_p = model$f(net_h_p)
+    
+    # Output layer
+    net_o_p = model$output %*% c(as.numeric(f_net_h_p), 1)
+    f_net_o_p = model$f(net_o_p)
+ 
+    # Results
+    ret = list()
+    ret$net_h_p = net_h_p
+    ret$net_o_p = net_o_p
+    ret$f_net_h_p = f_net_h_p
+    ret$f_net_o_p = f_net_o_p
+ 
+    return (ret)
+ }
> 
> mlp.backpropagation <- function(model,
+                                 dataset,
+                                 eta=0.1,
+                                 threshold=1e-4) {
+ 
+     squaredError = 2 * threshold
+     counter = 0
+ 
+     while(squaredError > threshold) {
+         squaredError = 0
+  
+         for (p in 1:nrow(dataset)) {
+             Xp = as.numeric(dataset[p, 1:model$input.length])
+             Yp = as.numeric(dataset[p,
+                     (model$input.length+1):ncol(dataset)])
+ 
+             results = mlp.forward(model, Xp)
+             Op = results$f_net_o_p
+ 
+             # Calculando o erro
+             error = Yp - Op
+ 
+             squaredError = squaredError + sum(error^2)
+ 
+             delta_o_p = error * model$df_dnet(results$f_net_o_p)
+         
+             w_o_kj = model$output[,1:model$hidden.length]
+             delta_h_p = 
+                 as.numeric(model$df_dnet(results$f_net_h_p)) *
+                     (as.numeric(delta_o_p) %*% w_o_kj)
+ 
+             model$output = model$output +
+                 eta*(delta_o_p%*%as.vector(c(results$f_net_h_p,1)))
+             model$hidden = model$hidden +
+                 eta*(t(delta_h_p) %*% as.vector(c(Xp,1)))
+         }
+         squaredError = squaredError / nrow(dataset)
+ 
+         cat("Erro médio quadrado = ", squaredError, "\n")
+ 
+         counter = counter + 1
+     }
+     cat("Base treinada Daniel, SEU GOSTOSO!\n")
+     ret = list()
+     ret$model = model
+     ret$counter = counter
+ 
+     return (ret)
+ }
> 
> 
> dataset = read.csv('__dataset.csv', header=F, skip=1)
> dataset <- dataset[c(1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 8)]
> ids = sample(1:nrow(dataset), size=33)
> training = dataset[ids,]
> test = dataset[-ids,]
> model = mlp.architecture(input.length=14, output.length=1, hidden.length=15)
> trained = mlp.backpropagation(dataset=training, model=model, eta=0.5)
Erro médio quadrado =  0.03443379 
Erro médio quadrado =  0.005332292 
Erro médio quadrado =  0.002898081 
Erro médio quadrado =  0.001971572 
Erro médio quadrado =  0.001485883 
Erro médio quadrado =  0.001188145 
Erro médio quadrado =  0.0009875394 
Erro médio quadrado =  0.0008435049 
Erro médio quadrado =  0.0007352376 
Erro médio quadrado =  0.0006509864 
Erro médio quadrado =  0.0005836212 
Erro médio quadrado =  0.0005285692 
Erro médio quadrado =  0.0004827653 
Erro médio quadrado =  0.0004440794 
Erro médio quadrado =  0.0004109863 
Erro médio quadrado =  0.0003823656 
Erro médio quadrado =  0.0003573758 
Erro médio quadrado =  0.0003353735 
Erro médio quadrado =  0.0003158578 
Erro médio quadrado =  0.0002984335 
Erro médio quadrado =  0.0002827846 
Erro médio quadrado =  0.0002686553 
Erro médio quadrado =  0.0002558365 
Erro médio quadrado =  0.0002441556 
Erro médio quadrado =  0.0002334689 
Erro médio quadrado =  0.0002236557 
Erro médio quadrado =  0.0002146142 
Erro médio quadrado =  0.0002062577 
Erro médio quadrado =  0.0001985117 
Erro médio quadrado =  0.0001913123 
Erro médio quadrado =  0.0001846043 
Erro médio quadrado =  0.0001783393 
Erro médio quadrado =  0.0001724754 
Erro médio quadrado =  0.0001669755 
Erro médio quadrado =  0.000161807 
Erro médio quadrado =  0.0001569412 
Erro médio quadrado =  0.0001523524 
Erro médio quadrado =  0.000148018 
Erro médio quadrado =  0.0001439174 
Erro médio quadrado =  0.0001400324 
Erro médio quadrado =  0.0001363466 
Erro médio quadrado =  0.0001328452 
Erro médio quadrado =  0.0001295149 
Erro médio quadrado =  0.0001263434 
Erro médio quadrado =  0.0001233199 
Erro médio quadrado =  0.0001204342 
Erro médio quadrado =  0.0001176773 
Erro médio quadrado =  0.0001150408 
Erro médio quadrado =  0.000112517 
Erro médio quadrado =  0.0001100989 
Erro médio quadrado =  0.0001077801 
Erro médio quadrado =  0.0001055547 
Erro médio quadrado =  0.0001034171 
Erro médio quadrado =  0.0001013623 
Erro médio quadrado =  9.938566e-05 
Base treinada Daniel, SEU GOSTOSO!
> write.csv(trained$model$hidden, file="hidden.csv", row.names=FALSE)
> write.csv(trained$model$output, file="output.csv", row.names=FALSE)
> 
> proc.time()
  usuário   sistema decorrido 
    0.713     0.055     0.756 
